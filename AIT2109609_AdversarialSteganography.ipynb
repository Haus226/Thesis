{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:44:52.930443Z",
     "iopub.status.busy": "2024-12-12T16:44:52.930095Z",
     "iopub.status.idle": "2024-12-12T16:45:01.06015Z",
     "shell.execute_reply": "2024-12-12T16:45:01.059053Z",
     "shell.execute_reply.started": "2024-12-12T16:44:52.930414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install piq sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T16:45:01.062596Z",
     "iopub.status.busy": "2024-12-12T16:45:01.062234Z",
     "iopub.status.idle": "2024-12-12T16:45:01.068681Z",
     "shell.execute_reply": "2024-12-12T16:45:01.067861Z",
     "shell.execute_reply.started": "2024-12-12T16:45:01.062566Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def softsign(x):\n",
    "    return x / (1 + x.abs())\n",
    "\n",
    "def sign(x):\n",
    "    return x.sign()\n",
    "\n",
    "def tanh(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 2 * x.sigmoid() - 1\n",
    "\n",
    "def clipped_linear(x):\n",
    "    return torch.clamp(x, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "ACTIVATION = {\n",
    "    \"sign\":sign,\n",
    "    \"softsign\":softsign,\n",
    "    \"tanh\":tanh,\n",
    "    \"sigmoid\":sigmoid,\n",
    "    \"linear\":clipped_linear,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:45:01.070583Z",
     "iopub.status.busy": "2024-12-12T16:45:01.069961Z",
     "iopub.status.idle": "2024-12-12T16:45:04.169848Z",
     "shell.execute_reply": "2024-12-12T16:45:04.169134Z",
     "shell.execute_reply.started": "2024-12-12T16:45:01.070555Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import json, os\n",
    "from piq.ssim import ssim \n",
    "from piq.fsim import fsim\n",
    "from piq.psnr import psnr\n",
    "from piq.vif import vif_p\n",
    "from piq.ms_ssim import multi_scale_ssim\n",
    "from piq.iw_ssim import information_weighted_ssim\n",
    "from piq.mdsi import mdsi\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def compute_metrics(img, adv_img, verbose=False):\n",
    "    '''\n",
    "    return: ssim, psnr, fsim, iw-ssim, ms-ssim, mdsi, vifp, mse, mae\n",
    "    '''\n",
    "    _ssim = ssim(adv_img, img, data_range=1.0).item()\n",
    "    _psnr = psnr(adv_img, img, data_range=1.0).item()\n",
    "    _fsim = fsim(adv_img, img, data_range=1.0).item()\n",
    "    _iw_ssim = information_weighted_ssim(adv_img, img, data_range=1.0).item()\n",
    "    _ms_ssim = multi_scale_ssim(adv_img, img, data_range=1.0).item()\n",
    "    _mdsi = mdsi(adv_img, img, data_range=1.0).item()\n",
    "    _vifp = vif_p(adv_img, img, data_range=1.0).item()\n",
    "    _mse = float(torch.mean((img - adv_img) ** 2).cpu())\n",
    "    _mae = float(torch.mean(torch.abs(img - adv_img)).cpu())\n",
    "    if verbose: \n",
    "        print(f'SSIM: {_ssim}')\n",
    "        print(f'PSNR: {_psnr}')\n",
    "        print(f'FSIM: {_fsim}')\n",
    "        print(f'IW-SSIM: {_iw_ssim}')\n",
    "        print(f'MS-SSIM: {_ms_ssim}')\n",
    "        print(f'MDSI: {_mdsi}')\n",
    "        print(f'VIFp: {_vifp}')\n",
    "        print(f'MSE: {_mse}')\n",
    "        print(f'MAE: {_mae}')\n",
    "    return [_ssim, _psnr, _fsim, _iw_ssim, _ms_ssim, _mdsi, _vifp, _mse, _mae]\n",
    "\n",
    "def display_result(m, att, targeted, metrics, metrics_average):\n",
    "    t = PrettyTable([\"ITEM\", \"VALUE\"])\n",
    "    t.add_row(['METHOD', f\"{m}_{att}\"])\n",
    "    t.add_row([\"TARGETED\", targeted])\n",
    "    for idx in range(len(metrics)):\n",
    "        t.add_row([metrics[idx], metrics_average[idx]])\n",
    "    print(t)      \n",
    "\n",
    "from PIL import Image\n",
    "def save_adv(adv, path):\n",
    "    # tiff.imwrite(f\"{path.replace('.png', '.tiff')}\", adv)\n",
    "    img = Image.fromarray(adv, mode=\"RGB\")\n",
    "    img.save(path)\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(s1, s2):\n",
    "    s1 =  s1.lower().strip().replace(\" \", \"\")\n",
    "    s2 =  s2.lower().strip().replace(\" \", \"\")\n",
    "    embedding1 = model.encode(s1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(s2, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return cosine_similarity.item()\n",
    "\n",
    "# Default using retain punc.\n",
    "def compute_cosine_similarity(s1, s2):\n",
    "    s1 =  s1.lower().strip().replace(\" \", \"\")\n",
    "    s2 =  s2.lower().strip().replace(\" \", \"\")\n",
    "    embedding1 = model.encode(s1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(s2, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    return cosine_similarity.item()\n",
    "\n",
    "import string\n",
    "# def compute_cosine_similarity(s1, s2, model_name):\n",
    "#     s1 = s1.lower().strip().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "#     s2 = s2.lower().strip().translate(str.maketrans(\"\", \"\", string.punctuation))    \n",
    "#     embedding1 = model.encode(s1, convert_to_tensor=True)\n",
    "#     embedding2 = model.encode(s2, convert_to_tensor=True)\n",
    "\n",
    "#     # Compute cosine similarity\n",
    "#     cosine_similarity = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "#     return cosine_similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:45:04.171366Z",
     "iopub.status.busy": "2024-12-12T16:45:04.171015Z",
     "iopub.status.idle": "2024-12-12T16:45:04.178509Z",
     "shell.execute_reply": "2024-12-12T16:45:04.177539Z",
     "shell.execute_reply.started": "2024-12-12T16:45:04.171336Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VLMDataset(Dataset):\n",
    "    def __init__(self, img_file, text_file, image_dir, num=100, processor=None):\n",
    "        self.img_file = pd.read_csv(img_file)[:num]\n",
    "        self.text_file = pd.read_csv(text_file, encoding=\"iso-8859-1\")[:num]\n",
    "        self.image_dir = image_dir\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.img_file.loc[idx, 'ImageId']) + \".png\"\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.processor(images=image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "        target_text = self.text_file.loc[idx, \"Target\"]\n",
    "        processed_target_text = self.processor(text=target_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        return image_path, image, target_text, processed_target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:52:17.541414Z",
     "iopub.status.busy": "2024-12-12T16:52:17.541063Z",
     "iopub.status.idle": "2024-12-12T16:52:17.590527Z",
     "shell.execute_reply": "2024-12-12T16:52:17.589682Z",
     "shell.execute_reply.started": "2024-12-12T16:52:17.541381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "class Attack(ABC):\n",
    "    def __init__(self, \n",
    "                alpha, \n",
    "                eps, \n",
    "                mean=None, std=None,\n",
    "                n_iter=10,\n",
    "                device=\"cuda\",\n",
    "                activation:str=\"sign\",\n",
    "                ) -> None:\n",
    "        \n",
    "        self.n_iter = n_iter\n",
    "        self.device = device\n",
    "        if mean is not None:\n",
    "            self.mean = torch.tensor(mean).view(1, 3, 1, 1).to(self.device)\n",
    "        else:\n",
    "            self.mean = torch.tensor([0, 0, 0]).view(1, 3, 1, 1).to(self.device)\n",
    "        if std is not None:\n",
    "            self.std = torch.tensor(std).view(1, 3, 1, 1).to(self.device)\n",
    "            adjustment = [(1 / 255) / s for s in std]\n",
    "        else:\n",
    "            self.std = torch.tensor([1, 1, 1]).view(1, 3, 1, 1).to(self.device)\n",
    "            adjustment = [1, 1, 1]\n",
    "\n",
    "        self.ad_alpha = alpha * torch.tensor(adjustment, device=device).view(1, 3, 1, 1)\n",
    "        self.ad_eps = eps * torch.tensor(adjustment, device=device).view(1, 3, 1, 1)\n",
    "\n",
    "        self.perturbation = None\n",
    "        if activation not in ACTIVATION:\n",
    "            raise NotImplementedError(f\"Please implement {activation} function in activation.py\")\n",
    "        self.activation_name = activation\n",
    "        self.activation = ACTIVATION[activation]\n",
    "        self.grad = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def init_components(self):\n",
    "        pass\n",
    "    \n",
    "    def earlystop(self, model, adv, processor):\n",
    "        generated_ids = model.generate(pixel_values=adv)\n",
    "        generated_caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        return generated_caption\n",
    "\n",
    "    def nesterov(self, adv, images):\n",
    "        return adv\n",
    "\n",
    "    def forward(self, model, images, target_texts, processed_target_texts, processor, \n",
    "                verbose_steps=100):\n",
    "        images = images.to(self.device)\n",
    "        processed_target_texts = processed_target_texts.to(self.device)\n",
    "        self.perturbation = torch.zeros_like(images).to(self.device)\n",
    "        self.init_components(images)\n",
    "        adv = images.detach().clone().to(self.device)\n",
    "        step = 0\n",
    "        generated_captions = []\n",
    "        for idx in range(self.n_iter):\n",
    "            # adv.requires_grad = True\n",
    "\n",
    "            # Initialize NAG\n",
    "            adv_nes = self.nesterov(adv, images)\n",
    "            adv_nes.requires_grad = True\n",
    "            outputs = model(pixel_values=adv_nes, input_ids=processed_target_texts, labels=processed_target_texts\n",
    "                           )\n",
    "            loss = -outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            self.grad = adv_nes.grad\n",
    "            self.grad = self.grad / torch.mean(torch.abs(self.grad), dim=(1, 2, 3), keepdim=True)\n",
    "            adv = self.update(adv, idx)\n",
    "            adv = self.clip(adv, images).detach()\n",
    "            generated_caption = self.earlystop(model, adv, processor)    \n",
    "            cos_sim, g, t = compute_cosine_similarity(generated_caption, target_texts)   \n",
    "            generated_captions.append(generated_caption)\n",
    "            if (g == t) or cos_sim >= 0.99:\n",
    "                print(f'Step {idx + 1}, Loss: {loss.item()}')\n",
    "                print(f'Similarity: {cos_sim}')\n",
    "                print(f\"Caption: {generated_caption}\")\n",
    "                break\n",
    "            step = idx\n",
    "            if (idx + 1) % verbose_steps == 0:\n",
    "                print(f'Step {idx + 1}, Loss: {loss.item()}')\n",
    "                print(f'Similarity: {cos_sim}')\n",
    "                print(f\"Caption: {generated_caption}\")\n",
    "\n",
    "        return adv.detach(), generated_captions, loss.detach().item(), self.perturbation.detach(), step + 1\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, adv, idx):\n",
    "        pass\n",
    "\n",
    "    def clip(self, adv, images):\n",
    "        delta = torch.clamp(adv - images, min=-self.ad_eps, max=self.ad_eps)\n",
    "        self.perturbation = delta\n",
    "        adv_ = images + delta\n",
    "        adv_ = adv_ * self.std + self.mean        \n",
    "        adv_ = torch.clamp(adv_, 0, 1)\n",
    "        adv_ = (adv_ - self.mean) / self.std\n",
    "        return adv_\n",
    "\n",
    "class Momentum(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None,  n_iter=10, device=\"cuda\", \n",
    "                beta=1.0,\n",
    "                activation=\"sign\", \n",
    "                ):\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.beta = beta\n",
    "        self.momentum = None\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.momentum = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        g = self.beta * self.momentum + self.grad\n",
    "        self.momentum = g\n",
    "        return adv + self.ad_alpha * self.activation(g)\n",
    "    \n",
    "class Nesterov(Momentum):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\", \n",
    "                beta=1.0,\n",
    "                activation=\"sign\"\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta, activation)\n",
    "\n",
    "    def nesterov(self, adv, images):\n",
    "        adv_nes = adv + self.beta * self.ad_alpha * self.activation(self.momentum)\n",
    "        return self.clip(adv_nes, images)\n",
    "    \n",
    "class AdaGrad(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\", \n",
    "                delta = 1e-8,\n",
    "                activation=\"softsign\"\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.delta = delta\n",
    "        self.squared_grad = None\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.squared_grad = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.squared_grad = self.squared_grad + self.grad ** 2\n",
    "        g = self.grad / (torch.sqrt(self.squared_grad) + self.delta)\n",
    "        return adv + self.ad_alpha * self.activation(g)\n",
    "    \n",
    "class AdaDelta(AdaGrad):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta=0.9, delta=1e-6,\n",
    "                activation=\"softsign\", \n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, delta, activation)\n",
    "        self.beta = beta\n",
    "        self.squared_x = None\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.squared_grad = torch.zeros_like(x).to(self.device)\n",
    "        self.squared_x = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.squared_grad = self.beta * self.squared_grad + (1 - self.beta) * self.grad ** 2\n",
    "        delta_x = torch.sqrt((self.squared_x + self.delta) / (self.squared_grad + self.delta)) * self.grad\n",
    "        self.squared_x = self.beta * self.squared_x + (1 - self.beta) * delta_x ** 2\n",
    "        return adv + self.activation(delta_x)\n",
    "    \n",
    "class RMSprop(AdaGrad):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta=0.99, delta=1e-8, \n",
    "                activation=\"softsign\"\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, delta, activation)\n",
    "        self.beta = beta\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.squared_grad = self.beta * self.squared_grad + (1 - self.beta) * self.grad ** 2\n",
    "        g = self.grad / (torch.sqrt(self.squared_grad) + self.delta)\n",
    "        return adv + self.ad_alpha * self.activation(g)\n",
    "    \n",
    "class Adam(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\"\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.momentum_1 = torch.zeros_like(x).to(self.device)\n",
    "        self.momentum_2 = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * self.grad ** 2\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        g = (b_momentum_1 / (torch.sqrt(b_momentum_2) + self.delta))\n",
    "        return adv + self.ad_alpha * self.activation(g)\n",
    "\n",
    "class AdaBelief(Adam):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\",\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta_1, beta_2, delta, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * (self.grad - self.momentum_1) ** 2 + self.delta\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        g = (b_momentum_1 / (torch.sqrt(b_momentum_2) + self.delta))\n",
    "        adv = adv + self.ad_alpha * self.activation(g)\n",
    "        return adv\n",
    "\n",
    "class NAdam(Adam):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\",\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta_1, beta_2, delta, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * self.grad ** 2\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        g = (self.beta_1 * b_momentum_1 + (1 - self.beta_1) * self.grad / (1 - self.beta_1 ** (idx + 1))) / (torch.sqrt(b_momentum_2) + self.delta)\n",
    "        adv = adv + self.ad_alpha * self.activation(g)\n",
    "        return adv\n",
    "    \n",
    "class Adan(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.02, beta_2=0.08, beta_3=0.01, delta=1e-8, \n",
    "                activation=\"softsign\",\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.beta_3 = beta_3\n",
    "        self.delta = delta\n",
    "        self.m_k, self.v_k, self.n_k = None, None, None\n",
    "        self.g_previous = None\n",
    "    \n",
    "    def init_components(self, x):\n",
    "        self.m_k = torch.zeros_like(x).to(self.device)\n",
    "        self.v_k = torch.zeros_like(x).to(self.device)\n",
    "        self.n_k = torch.zeros_like(x).to(self.device)\n",
    "        self.g_previous = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        bias_correction1 = 1.0 - math.pow(self.beta_1, idx + 1)\n",
    "        bias_correction2 = 1.0 - math.pow(self.beta_2, idx + 1)\n",
    "        bias_correction3_sq = math.sqrt(1.0 - math.pow(self.beta_3, idx + 1))\n",
    "        self.m_k = (1 - self.beta_1) * self.m_k + self.beta_1 * self.grad\n",
    "        self.v_k = (1 - self.beta_2) * self.v_k + self.beta_2 * (self.grad - self.g_previous)\n",
    "        self.n_k = (1 - self.beta_3) * self.n_k + self.beta_3 * (self.grad + (1 - self.beta_2) * (self.grad - self.g_previous)) ** 2\n",
    "        self.g_previous = self.grad.clone()\n",
    "        de_norm = self.n_k.sqrt().div_(bias_correction3_sq).add_(self.delta)\n",
    "        g1 = self.m_k / de_norm / bias_correction1\n",
    "        g2 = self.v_k * (1 - self.beta_2) / de_norm / bias_correction2\n",
    "\n",
    "        return adv + self.ad_alpha * self.activation(g1 + g2)\n",
    "    \n",
    "class Adai(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "            beta_1=0.1, beta_2=0.99, dampening=1.0, delta=1e-3, \n",
    "            activation=\"softsign\",\n",
    "            ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.dampening = dampening\n",
    "        self.delta = delta\n",
    "        self.exp_avg, self.exp_avg_sq, self.beta1_prod = None, None, None\n",
    "        self.param_size = None\n",
    "\n",
    "    def init_components(self, images):\n",
    "        self.exp_avg = torch.zeros_like(images)\n",
    "        self.exp_avg_sq = torch.zeros_like(images)\n",
    "        self.beta1_prod = torch.ones_like(images)\n",
    "        self.param_size = images.numel()\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        exp_avg_sq_hat_sum = 0.0\n",
    "        self.exp_avg_sq.mul_(self.beta_2).addcmul_(self.grad, self.grad, value=1.0 - self.beta_2)\n",
    "        bias_correction2 = 1 - self.beta_2 ** (idx + 1)\n",
    "        exp_avg_sq_hat_sum += self.exp_avg_sq.sum() / bias_correction2\n",
    "        exp_avg_sq_hat_mean = exp_avg_sq_hat_sum / self.param_size\n",
    "\n",
    "        exp_avg_sq_hat = self.exp_avg_sq / bias_correction2\n",
    "\n",
    "        beta1 = (\n",
    "            1.0\n",
    "            - (exp_avg_sq_hat / exp_avg_sq_hat_mean).pow_(1.0 / (3.0 - 2.0 * self.dampening)).mul_(self.beta_1)\n",
    "        ).clamp_(0.0, 1.0 - self.delta)\n",
    "        beta3 = (1.0 - beta1).pow_(self.dampening)\n",
    "\n",
    "        self.beta1_prod.mul_(beta1)\n",
    "\n",
    "        self.exp_avg.mul_(beta1).addcmul_(beta3, self.grad)\n",
    "        exp_avg_hat = self.exp_avg.div(1.0 - self.beta1_prod).mul_(math.pow(self.beta_1, 1. - self.dampening))\n",
    "\n",
    "        return adv + self.ad_alpha * self.activation(exp_avg_hat)\n",
    "\n",
    "class Yogi(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, initial_accumulator=1e-6, delta=1e-3, \n",
    "                activation=\"softsign\",\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "        self.initial_accumulator = initial_accumulator\n",
    "        self.exp_avg, self.exp_avg_sq = None, None\n",
    "\n",
    "    def init_components(self, images):\n",
    "        self.exp_avg = torch.full_like(images, fill_value=self.initial_accumulator)\n",
    "        self.exp_avg_sq = torch.full_like(images, fill_value=self.initial_accumulator)\n",
    "\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        bias_correction2_sq = math.sqrt(1.0 - math.pow(self.beta_2, idx + 1))\n",
    "        grad_sq = self.grad * self.grad\n",
    "        self.exp_avg.mul_(self.beta_1).add_(self.grad, alpha=1.0 - self.beta_1)\n",
    "        self.exp_avg_sq.addcmul_((self.exp_avg_sq - grad_sq).sign_(), grad_sq, value=-(1.0 - self.beta_2))\n",
    "        de_nom = self.exp_avg_sq.sqrt().div_(bias_correction2_sq).add_(self.delta)\n",
    "        return adv + self.ad_alpha * self.activation(self.exp_avg / de_nom)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T17:07:38.997771Z",
     "iopub.status.busy": "2024-12-12T17:07:38.997438Z",
     "iopub.status.idle": "2024-12-12T17:07:46.597615Z",
     "shell.execute_reply": "2024-12-12T17:07:46.596177Z",
     "shell.execute_reply.started": "2024-12-12T17:07:38.997742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration, set_seed\n",
    "import torch, tqdm\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd, os\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import GitProcessor, GitForCausalLM\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM \n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "\n",
    "TIME = datetime.now().strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "N_ITER = 500\n",
    "EPS = 3\n",
    "SAVE_DIR = os.getcwd() + f'/{TIME.replace(\"/\", \"_\").replace(\":\", \"_\")}_{N_ITER}_{EPS}'\n",
    "# INPUT_DIR = r\"C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\"\n",
    "# INPUT_META = r\"C:\\Users\\User\\Desktop\\Thesis\\common.csv\"\n",
    "# TARGET_TEXT = r\"C:\\Users\\User\\Desktop\\Thesis_\\multimodal\\BLIP_normal.csv\"\n",
    "INPUT_DIR = \"/kaggle/input/nips-2017-adversarial-learning-development-set/images\"\n",
    "INPUT_META = \"/kaggle/input/thesis-common/common.csv\"\n",
    "TARGET_TEXT = \"/kaggle/input/image-captioning-attack-dataset/BLIP_sensitive.csv\"\n",
    "\n",
    "# Load BLIP model and processor\n",
    "set_seed(226)\n",
    "# Model configurations with their corresponding Hugging Face repositories\n",
    "model_configs = {\n",
    "\n",
    "    \"GIT-Large\": {\n",
    "        \"model_name\": \"microsoft/git-large\",\n",
    "        \"processor\": GitProcessor\n",
    "    },\n",
    "    \"BLIP-Large\": {\n",
    "        \"model_name\": \"Salesforce/blip-image-captioning-large\",\n",
    "        \"processor\": BlipProcessor\n",
    "    },\n",
    "\n",
    "    \"BLIP-Base\": {\n",
    "        \"model_name\": \"Salesforce/blip-image-captioning-base\",\n",
    "        \"processor\": BlipProcessor\n",
    "    },\n",
    "\n",
    "    \"GIT-Base\": {\n",
    "        \"model_name\": \"microsoft/git-base\",\n",
    "        \"processor\": GitProcessor\n",
    "    },\n",
    "    \"FuseCap\": {\n",
    "        \"model_name\": \"noamrot/FuseCap\",\n",
    "        \"processor\": AutoProcessor\n",
    "    },\n",
    "\n",
    "}\n",
    "# Initialize dictionaries to hold models and processors\n",
    "models = {}\n",
    "processors = {}\n",
    "\n",
    "# Load all models and processors\n",
    "for model_key, config in model_configs.items():\n",
    "    print(f\"Loading {model_key}...\")\n",
    "    # Load the model\n",
    "    if \"GIT\" in model_key:\n",
    "        models[model_key] = GitForCausalLM.from_pretrained(config[\"model_name\"]).to(\"cuda\").eval()\n",
    "    elif \"BLIP\" in model_key:\n",
    "        models[model_key] = BlipForConditionalGeneration.from_pretrained(config[\"model_name\"]).to(\"cuda\").eval()\n",
    "    elif \"FuseCap\" in model_key:\n",
    "        models[model_key] =  BlipForConditionalGeneration.from_pretrained(config[\"model_name\"]).to(\"cuda\").eval()\n",
    "    # Load the processor\n",
    "    processors[model_key] = config[\"processor\"].from_pretrained(config[\"model_name\"])\n",
    "    print(f\"{model_key} loaded successfully.\\n\")\n",
    "    \n",
    "\n",
    "inv_transforms = {}\n",
    "\n",
    "for model_key, processor in processors.items():\n",
    "    mean = processor.image_processor.image_mean if hasattr(processor, \"image_processor\") else [0.5, 0.5, 0.5]\n",
    "    std = processor.image_processor.image_std if hasattr(processor, \"image_processor\") else [0.5, 0.5, 0.5]\n",
    "    inv_transforms[model_key] = {\n",
    "        \"inv_transform\":transforms.Compose([\n",
    "                            transforms.Normalize(mean=[-m / s for m, s in zip(mean, std)],\n",
    "                                std=[1 / s for s in std])\n",
    "        ]),\n",
    "        \"mean\":mean, \n",
    "        \"std\":std}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for crafting_model_key, crafting_model in models.items():\n",
    "\n",
    "    crafting_processor = processors[crafting_model_key]\n",
    "    dataset = VLMDataset(INPUT_META, TARGET_TEXT, INPUT_DIR, 20, processor=crafting_processor)\n",
    "    dataloader = DataLoader(dataset, shuffle=False, batch_size=1)\n",
    "    crafting_inv_transform = inv_transforms[crafting_model_key][\"inv_transform\"]\n",
    "    mean = inv_transforms[crafting_model_key][\"mean\"]\n",
    "    std = inv_transforms[crafting_model_key][\"std\"]\n",
    "    act = \"linear\"\n",
    "    attack = {\n",
    "        \"Momentum\":Momentum(alpha=1, eps=EPS, mean=mean, std=std, n_iter=N_ITER, activation=act),\n",
    "        \"Nesterov\":Nesterov(alpha=1, eps=EPS, mean=mean, std=std, n_iter=N_ITER, activation=act),\n",
    "        \"Adam\":Adam(alpha=1, eps=EPS, mean=mean, std=std, n_iter=N_ITER, activation=act),\n",
    "        \"NAdam\":NAdam(alpha=1, eps=EPS, mean=mean, std=std, n_iter=N_ITER, activation=act),\n",
    "        \"AdaBelief\":AdaBelief(alpha=1, eps=EPS, mean=mean, std=std, n_iter=N_ITER, activation=act),\n",
    "    }\n",
    "    for attack_name, attack_method in attack.items():\n",
    "        results = {\n",
    "            \"CRAFTING_MODEL\": [],\n",
    "            \"IMAGE_PATH\": [], \"CRAFTED_CAPTION\": [], \"TARGETED_TEXT\": [],\n",
    "            \"SSIM\": [], \"PSNR\": [], \"FSIM\": [], \"IW-SSIM\": [], \"MS-SSIM\": [],\n",
    "            \"MDSI\": [], \"VIF_P\": [], \"MSE\": [], \"MAE\": [], \"SIMILARITY\": [],\n",
    "            \"STEP\": [], \"LOSS\": [], \"NOISE\": [], \"SUCCESS\": [],\n",
    "        }\n",
    "        evaluated_results = {\n",
    "            \"EVALUATION_MODEL\":[],\n",
    "            \"CRAFT_GENERATED_CAPTIONS\":[],\n",
    "            \"EVAL_GENERATED_CAPTIONS\":[],\n",
    "            \"TARGETED_CAPTIONS\":[],\n",
    "            \"CRAFTED_SIMILARITY\":[],\n",
    "            \"EVAL_SIMILARITY\":[]\n",
    "        }\n",
    "        metrics = list(results.keys())[4:13]\n",
    "\n",
    "        # Directory to save adversarial examples and results\n",
    "        output_dir = fr\"{SAVE_DIR}/{crafting_model_key}/{attack_name}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        progress = tqdm.tqdm(dataloader, desc=f\"{crafting_model_key}/{attack_name}\")\n",
    "        for image_paths, images, target_texts, processed_target_texts in progress:\n",
    "            # Unpack the data\n",
    "            image = images[0]  # (3, H, W)\n",
    "            processed_target_text = processed_target_texts[0]\n",
    "            target_text = target_texts[0]\n",
    "\n",
    "            # Generate adversarial example using the crafting model\n",
    "            adv, generated_captions, loss, perturb, steps = attack_method.forward(\n",
    "                crafting_model, image, target_text, processed_target_text, crafting_processor, 10\n",
    "            )\n",
    "            adv = crafting_inv_transform(adv[0]).clamp(0, 1)  # Denormalize adversarial image\n",
    "            adv_img_t = adv.cpu().numpy().transpose(1, 2, 0)  # Convert for saving\n",
    "            ori = crafting_inv_transform(image).to(\"cuda\").clamp(0, 1)\n",
    "            # Save the adversarial image\n",
    "            adv_img_t = np.clip(adv_img_t * 255, 0, 255).astype(np.uint8) \n",
    "            save_adv(adv_img_t, os.path.join(output_dir, os.path.basename(image_paths[0])))\n",
    "            computed_metrics = compute_metrics(ori, adv.unsqueeze(0), True)\n",
    "\n",
    "            # Remove all punctuations\n",
    "            g = generated_captions[-1].lower().replace(\" \", \"\").strip()\n",
    "            t = target_text.lower().replace(\" \", \"\").strip()\n",
    "            cos_sim = compute_cosine_similarity(g, t)   \n",
    "            \n",
    "            if g == t or cos_sim >= 0.99:\n",
    "                results[\"SUCCESS\"].append(1)\n",
    "            else:\n",
    "                results[\"SUCCESS\"].append(0)\n",
    "\n",
    "            for idx, metric_name in enumerate(metrics):\n",
    "                results[metric_name].append(computed_metrics[idx])\n",
    "\n",
    "            results[\"CRAFTING_MODEL\"].append(crafting_model_key)\n",
    "            results[\"STEP\"].append(steps)\n",
    "            results[\"LOSS\"].append(loss)\n",
    "            results[\"NOISE\"].append(torch.norm(perturb, 2).item())\n",
    "            results[\"IMAGE_PATH\"].append(image_paths[0])\n",
    "            results[\"CRAFTED_CAPTION\"].append(\"\\n\".join(generated_captions))\n",
    "            results[\"TARGETED_TEXT\"].append(target_text.lower())\n",
    "            results[\"SIMILARITY\"].append(cos_sim)\n",
    "\n",
    "            # Save the results to a CSV\n",
    "            output_file = os.path.join(output_dir, f\"{crafting_model_key}_{attack_name}_results.csv\")\n",
    "            pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "            print(f\"Checkpoint saved for {crafting_model_key} crafting with {attack_name} attack in {output_file}\")\n",
    "            \n",
    "            # Evaluate the adversarial sample across all models\n",
    "            for evaluation_model_key, evaluation_model in models.items():\n",
    "                evaluation_processor = processors[evaluation_model_key]\n",
    "                adv = torch.from_numpy(adv_img_t).permute(2, 0, 1)\n",
    "                # Preprocess adversarial image for the evaluation model\n",
    "                inputs = evaluation_processor(images=adv.unsqueeze(0), return_tensors=\"pt\").to(\"cuda\")\n",
    "                # Generate caption with the evaluation model\n",
    "                outputs = evaluation_model.generate(**inputs)\n",
    "                generated_caption = evaluation_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "                similarity = compute_cosine_similarity(generated_caption.lower().strip().replace(\" \", \"\"), t)\n",
    "\n",
    "                evaluated_results[\"EVALUATION_MODEL\"].append(evaluation_model_key)\n",
    "                evaluated_results[\"CRAFT_GENERATED_CAPTIONS\"].append(generated_captions[-1])\n",
    "                evaluated_results[\"EVAL_GENERATED_CAPTIONS\"].append(generated_caption)\n",
    "                evaluated_results[\"TARGETED_CAPTIONS\"].append(target_text)\n",
    "                evaluated_results[\"CRAFTED_SIMILARITY\"].append(cos_sim)\n",
    "                evaluated_results[\"EVAL_SIMILARITY\"].append(similarity)\n",
    "\n",
    "                # Print progress\n",
    "                progress.set_description(f\"{crafting_model_key}/{attack_name}/{sum(results['SUCCESS'])}\")\n",
    "                output_file = os.path.join(output_dir, f\"{crafting_model_key}_{attack_name}_eval_results.csv\")\n",
    "                pd.DataFrame(evaluated_results).to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1503,
     "sourceId": 2703,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5307098,
     "sourceId": 8821674,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6268657,
     "sourceId": 10153594,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
