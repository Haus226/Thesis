{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:45.153514Z",
     "iopub.status.busy": "2024-11-26T09:59:45.153168Z",
     "iopub.status.idle": "2024-11-26T09:59:55.115084Z",
     "shell.execute_reply": "2024-11-26T09:59:55.113767Z",
     "shell.execute_reply.started": "2024-11-26T09:59:45.153490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: piq in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from piq) (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torchvision>=0.10.0->piq) (1.24.3)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torchvision>=0.10.0->piq) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torchvision>=0.10.0->piq) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from torch==2.3.0->torchvision>=0.10.0->piq) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision>=0.10.0->piq) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision>=0.10.0->piq) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision>=0.10.0->piq) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\snaphealth\\lib\\site-packages (from sympy->torch==2.3.0->torchvision>=0.10.0->piq) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:55.118386Z",
     "iopub.status.busy": "2024-11-26T09:59:55.117776Z",
     "iopub.status.idle": "2024-11-26T09:59:58.102564Z",
     "shell.execute_reply": "2024-11-26T09:59:58.101910Z",
     "shell.execute_reply.started": "2024-11-26T09:59:55.118344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "class Dummy:\n",
    "    '''\n",
    "    Creating a dummy class to maintain consistency in function or method calls \n",
    "    when certain classes are None, useful in simplifying code logic\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DI:\n",
    "    def __init__(self, low, high, p:float=0.5, transform=nn.Identity) -> None:\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.p = p\n",
    "        self.transform = transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.p < random.random():\n",
    "            return x\n",
    "        # Random resize\n",
    "        rnd = torch.randint(low=self.low, high=self.high, size=(1, ))\n",
    "        rescaled = F.interpolate(x, size=(rnd, rnd), mode='bilinear')\n",
    "        # Calculate padding\n",
    "        h_rem = self.high - rnd\n",
    "        w_rem = self.high - rnd\n",
    "        pad_top = random.randint(0, h_rem)\n",
    "        pad_bottom = h_rem - pad_top\n",
    "        pad_left = random.randint(0, w_rem)\n",
    "        pad_right = w_rem - pad_left\n",
    "        # Apply padding\n",
    "        padded = F.pad(rescaled, (pad_left, pad_right, pad_top, pad_bottom), value=0)\n",
    "        return self.transform(padded)\n",
    "\n",
    "class TI:\n",
    "    def __init__(self, \n",
    "        kernel_size, \n",
    "        nsig,\n",
    "        device=\"cuda\"\n",
    "        ) -> None:\n",
    "        import scipy.stats as st\n",
    "        kern1d = st.norm.pdf(np.linspace(-nsig, nsig, kernel_size))\n",
    "        kernel_raw = np.outer(kern1d, kern1d)\n",
    "        kernel = kernel_raw / kernel_raw.sum()\n",
    "        stack_kernel = np.stack([kernel, kernel, kernel])\n",
    "        stack_kernel = np.expand_dims(stack_kernel, 1)\n",
    "        self.kernel = torch.from_numpy(stack_kernel).float().to(device)\n",
    "\n",
    "    def forward(self, grad):\n",
    "        return F.conv2d(grad, self.kernel, stride=1, padding=\"same\", groups=3)\n",
    "\n",
    "class Admix:\n",
    "    '''\n",
    "    Paper : Admix: Enhancing the Transferability of Adversarial Attacks\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                gamma=[1 / (2 ** i) for i in range(5)], \n",
    "                eta=0.2, \n",
    "                num_samples=3\n",
    "                ) -> None:\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        assert num_samples >= 1\n",
    "        self.num_samples = num_samples\n",
    "        if not isinstance(self.gamma, list):\n",
    "            self.m = 1\n",
    "        else:\n",
    "            self.m = len(self.gamma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        idxs = torch.arange(batch_size)\n",
    "        x_admix = []\n",
    "        t = x.clone()\n",
    "        if self.eta != 0:\n",
    "            for _ in range(self.num_samples):\n",
    "                shuffled_idxs = idxs[torch.randperm(batch_size)]\n",
    "                slave = x[shuffled_idxs]\n",
    "                x_admix.append(x + self.eta * slave)\n",
    "            x_admix = torch.cat(x_admix, dim=0)\n",
    "        else:\n",
    "            x_admix = t\n",
    "        return torch.cat([x_admix * gamma for gamma in self.gamma], dim=0) if self.gamma else x_admix\n",
    "\n",
    "class VT:\n",
    "    '''\n",
    "    Paper : \"Enhancing the Transferability of Adversarial Attacks through Variance Tuning\"\n",
    "    '''\n",
    "    def __init__(self, \n",
    "        num_samples,\n",
    "        bound,\n",
    "        dist,\n",
    "        admix=None, \n",
    "        dim=None,\n",
    "        ) -> None:\n",
    "        self.num_samples = num_samples\n",
    "        self.bound = bound\n",
    "        self.dim = dim\n",
    "        self.admix = admix\n",
    "        self.dist = dist\n",
    "        if not isinstance(admix, Dummy):\n",
    "            self.m = self.admix.m\n",
    "            self.n = self.admix.num_samples\n",
    "            self.gamma = self.admix.gamma\n",
    "        else:\n",
    "            self.m = self.n = 1\n",
    "\n",
    "    def forward(self, x, model, labels, target_labels=None, device=\"cuda\"): \n",
    "        if self.dist == \"uniform\":\n",
    "            perturbations = (torch.rand((self.num_samples, *x.shape), device=device) * 2 - 1) * self.bound.to(device)\n",
    "        elif self.dist == \"normal\":\n",
    "            perturbations = torch.randn((self.num_samples, *x.shape), device=device) * self.bound.to(device)\n",
    "        x_neighbors = x.unsqueeze(0) + perturbations  # Shape: (self.num_samples, batch_size, *x.shape[1:])\n",
    "        x_neighbors = x_neighbors.view(-1, *x.shape[1:])  # Flatten for batch processing\n",
    "        \n",
    "        x_neighbors = self.admix.forward(x_neighbors)\n",
    "        x_neighbors.retain_grad()\n",
    "    \n",
    "        outputs = model(self.dim.forward(x_neighbors))  # Outputs for all perturbed samples\n",
    "    \n",
    "        loss_fn = nn.CrossEntropyLoss()  # No reduction for per-sample loss\n",
    "        if target_labels is not None:\n",
    "            losses = -loss_fn(outputs, target_labels)\n",
    "        else:\n",
    "            losses = loss_fn(outputs, labels)\n",
    "    \n",
    "        grads = torch.autograd.grad(losses, x_neighbors, retain_graph=False, create_graph=False)[0]\n",
    "        grads = grads.mean(dim=0)\n",
    "    \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:58.104136Z",
     "iopub.status.busy": "2024-11-26T09:59:58.103797Z",
     "iopub.status.idle": "2024-11-26T09:59:58.239202Z",
     "shell.execute_reply": "2024-11-26T09:59:58.238230Z",
     "shell.execute_reply.started": "2024-11-26T09:59:58.104115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class Attack(ABC):\n",
    "    def __init__(self, \n",
    "                alpha, \n",
    "                eps, \n",
    "                mean=None, std=None,\n",
    "                n_iter=10,\n",
    "                device=\"cuda\",\n",
    "                activation:str=\"sign\",\n",
    "                dim=None,\n",
    "                tim=None,\n",
    "                admix=None,\n",
    "                vt=None,\n",
    "                ) -> None:\n",
    "        self.device = device\n",
    "        if mean is not None:\n",
    "            self.mean = torch.tensor(mean).view(1, 3, 1, 1).to(self.device)\n",
    "        else:\n",
    "            self.mean = torch.tensor([0, 0, 0]).view(1, 3, 1, 1).to(self.device)\n",
    "        if std is not None:\n",
    "            self.std = torch.tensor(std).view(1, 3, 1, 1).to(self.device)\n",
    "            adjustment = [(1 / 255) / s for s in std]\n",
    "        else:\n",
    "            self.std = torch.tensor([1, 1, 1]).view(1, 3, 1, 1).to(self.device)\n",
    "            adjustment = [1, 1, 1]\n",
    "\n",
    "        self.ad_alpha = alpha * torch.tensor(adjustment, device=device).view(1, 3, 1, 1)\n",
    "        self.ad_eps = eps * torch.tensor(adjustment, device=device).view(1, 3, 1, 1)\n",
    "        self.n_iter = n_iter\n",
    "        self.perturbation = None\n",
    "        if activation not in ACTIVATION:\n",
    "            raise NotImplementedError(f\"Please implement {activation} function in activation.py\")\n",
    "\n",
    "        self.activation_name = activation\n",
    "        self.activation = ACTIVATION[activation]\n",
    "        self.grad = None\n",
    "\n",
    "        self.dim = DI(**dim) if dim is not None else Dummy()\n",
    "        self.tim = TI(**tim) if tim is not None else Dummy()\n",
    "        self.admix = Dummy()\n",
    "        self.vt = Dummy()\n",
    "\n",
    "        if admix is not None:\n",
    "            self.admix = Admix(**admix)\n",
    "            self.m = self.admix.m\n",
    "            self.n = self.admix.num_samples\n",
    "            self.gamma = self.admix.gamma\n",
    "        else:\n",
    "            self.m = self.n = 1\n",
    "\n",
    "        if vt is not None:\n",
    "            self.vt = VT(vt[\"num_samples\"], (self.ad_eps * vt[\"bound\"]).view(1, 3, 1, 1).to(device), \n",
    "                        vt[\"dist\"],\n",
    "                        admix=self.admix, dim=self.dim)\n",
    "            self.N = self.vt.num_samples\n",
    "        else:\n",
    "            self.N = 1\n",
    "\n",
    "    @abstractmethod\n",
    "    def init_components(self):\n",
    "        pass\n",
    "\n",
    "    def nesterov(self, adv, images):\n",
    "        return adv\n",
    "\n",
    "    def forward(self, model, images, labels, target_labels=None):\n",
    "        early_stop = False      \n",
    "\n",
    "        labels_ = labels.repeat(self.m * self.n).to(self.device)\n",
    "        \n",
    "        images = images.to(self.device)\n",
    "        if target_labels is not None:\n",
    "            target_labels_ = target_labels.repeat(self.m * self.n).to(self.device)\n",
    "            vt_target_labels = target_labels_.repeat(self.N).to(self.device)\n",
    "\n",
    "        \n",
    "        vt_labels = labels_.repeat(self.N).to(self.device)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        v_grad = torch.zeros_like(images).to(self.device)\n",
    "        self.perturbation = torch.zeros_like(images).to(self.device)\n",
    "        self.init_components(images)\n",
    "        adv = images.detach().clone().to(self.device)\n",
    "        for idx in range(self.n_iter):\n",
    "            adv.requires_grad = True\n",
    "            # Initialize NAG\n",
    "            adv_nes = self.nesterov(adv, images)\n",
    "            adv_ = self.admix.forward(adv_nes)\n",
    "            adv__ = self.dim.forward(adv_)\n",
    "            outputs = model(adv__)\n",
    "            l = -loss(outputs, target_labels_) if target_labels is not None else loss(outputs, labels_)\n",
    "            if early_stop:\n",
    "                if (target_labels is not None and outputs.max(1)[1] == target_labels_) or (target_labels is None and outputs.max(1)[1] != labels_):\n",
    "                    return adv_nes.detach(), outputs.max(1)[1], l.detach().item(), self.perturbation.detach(), idx + 1\n",
    "            noise = torch.autograd.grad(\n",
    "                l, adv, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "            if isinstance(self.admix, Admix):\n",
    "                noise = torch.sum(noise, dim=0) / (self.m * self.n)\n",
    "            self.grad = noise + v_grad\n",
    "            self.grad = self.tim.forward(self.grad)\n",
    "            self.grad = self.grad / torch.mean(torch.abs(self.grad), dim=(1, 2, 3), keepdim=True)\n",
    "            if isinstance(self.vt, VT):\n",
    "                v_grad = self.vt.forward(adv_nes, model, vt_labels, vt_target_labels if target_labels is not None else target_labels, self.device) - noise\n",
    "            adv = self.update(adv, idx)\n",
    "            adv = self.clip(adv, images).detach()\n",
    "        return adv.detach(), model(adv).max(1)[1], l.mean().detach().item(), self.perturbation.detach(), self.n_iter \n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, adv, idx):\n",
    "        pass\n",
    "\n",
    "    def clip(self, adv, images):\n",
    "        delta = torch.clamp(adv - images, min=-self.ad_eps, max=self.ad_eps)\n",
    "        self.perturbation = delta\n",
    "        adv_ = images + delta\n",
    "        adv_ = adv_ * self.std + self.mean        \n",
    "        adv_ = torch.clamp(adv_, 0, 1)\n",
    "        adv_ = (adv_ - self.mean) / self.std\n",
    "        return adv_\n",
    "\n",
    "class Momentum(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None,  n_iter=10, device=\"cuda\", \n",
    "                beta=1.0,\n",
    "                activation=\"sign\", \n",
    "                dim:DI=None, tim:TI=None, admix:Admix=None, vt:VT=None\n",
    "                ):\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation, dim, tim, admix, vt)\n",
    "        self.beta = beta\n",
    "        self.momentum = None\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.momentum = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        g = self.beta * self.momentum + self.grad\n",
    "        self.momentum = g\n",
    "        return adv + self.ad_alpha * self.activation(g)\n",
    "\n",
    "class Nesterov(Momentum):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\", \n",
    "                beta=1.0,\n",
    "                activation=\"sign\",\n",
    "                dim:DI=None, tim:TI=None, admix:Admix=None, vt:VT=None\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta, activation, dim, tim, admix, vt)\n",
    "\n",
    "    def nesterov(self, adv, images):\n",
    "        adv_nes = adv + self.beta * self.ad_alpha * self.activation(self.momentum)\n",
    "        return self.clip(adv_nes, images)\n",
    "\n",
    "class Adam(Attack):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\",\n",
    "                dim:DI=None, tim:TI=None, admix:Admix=None, vt:VT=None\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, activation, dim, tim, admix, vt)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "        self.g = None\n",
    "\n",
    "    def init_components(self, x):\n",
    "        self.g = torch.zeros_like(x).to(self.device)\n",
    "        self.momentum_1 = torch.zeros_like(x).to(self.device)\n",
    "        self.momentum_2 = torch.zeros_like(x).to(self.device)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * self.grad ** 2\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        self.g = (b_momentum_1 / (torch.sqrt(b_momentum_2) + self.delta))\n",
    "        return adv + self.ad_alpha * self.activation(self.g)\n",
    "\n",
    "class AdaBelief(Adam):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\",\n",
    "                dim:DI=None, tim:TI=None, admix:Admix=None, vt:VT=None\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta_1, beta_2, delta, activation, dim, tim, admix, vt)\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * (self.grad - self.momentum_1) ** 2 + self.delta\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        self.g = (b_momentum_1 / (torch.sqrt(b_momentum_2) + self.delta))\n",
    "        adv = adv + self.ad_alpha * self.activation(self.g)\n",
    "        return adv\n",
    "\n",
    "class NAdam(Adam):\n",
    "    def __init__(self, alpha=1, eps=5, mean=None, std=None, n_iter=10, device=\"cuda\",\n",
    "                beta_1=0.9, beta_2=0.999, delta=1e-8,\n",
    "                activation=\"softsign\",\n",
    "                dim:DI=None, tim:TI=None, admix:Admix=None, vt:VT=None\n",
    "                ) -> None:\n",
    "        super().__init__(alpha, eps, mean, std, n_iter, device, beta_1, beta_2, delta, activation, dim, tim, admix, vt)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.delta = delta\n",
    "\n",
    "    def update(self, adv, idx):\n",
    "        self.momentum_1 = self.beta_1 * self.momentum_1 + (1 - self.beta_1) * self.grad\n",
    "        self.momentum_2 = self.beta_2 * self.momentum_2 + (1 - self.beta_2) * self.grad ** 2\n",
    "        b_momentum_1 = self.momentum_1 / (1 - self.beta_1 ** (idx + 1))\n",
    "        b_momentum_2 = self.momentum_2 / (1 - self.beta_2 ** (idx + 1))\n",
    "        self.g = (self.beta_1 * b_momentum_1 + (1 - self.beta_1) * self.grad / (1 - self.beta_1 ** (idx + 1))) / (torch.sqrt(b_momentum_2) + self.delta)\n",
    "        adv = adv + self.ad_alpha * self.activation(self.g)\n",
    "        return adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:58.241250Z",
     "iopub.status.busy": "2024-11-26T09:59:58.240982Z",
     "iopub.status.idle": "2024-11-26T09:59:58.733183Z",
     "shell.execute_reply": "2024-11-26T09:59:58.732479Z",
     "shell.execute_reply.started": "2024-11-26T09:59:58.241230Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import tqdm, imageio, tifffile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class ImageCSVDataset(Dataset):\n",
    "    '''\n",
    "    return: path, image, label, target_label\n",
    "    '''\n",
    "    def __init__(self, csv_file, image_dir, num=846, transform=None, decrypt=None, mode=\"validate\"):\n",
    "        self.data = pd.read_csv(csv_file)[:num] if mode == \"validate\" else pd.read_csv(csv_file)[num:800]\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        if decrypt is None:\n",
    "            self.format = \".png\"\n",
    "        else:\n",
    "            self.format = \".tiff\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.data.iloc[idx]['ImageId']) + self.format\n",
    "        if self.format == \".png\":\n",
    "            image = Image.open(image_path).convert('RGB')  # Assuming RGB images\n",
    "        else:\n",
    "            image = imageio.imread(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.data.iloc[idx]['TrueLabel'] - 1\n",
    "        target_label = self.data.iloc[idx]['TargetClass'] - 1\n",
    "        return image_path, image, label, target_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:58.734535Z",
     "iopub.status.busy": "2024-11-26T09:59:58.734210Z",
     "iopub.status.idle": "2024-11-26T09:59:59.980797Z",
     "shell.execute_reply": "2024-11-26T09:59:59.979858Z",
     "shell.execute_reply.started": "2024-11-26T09:59:58.734515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "low = 224\n",
    "high = 330\n",
    "\n",
    "low32 = low + 32\n",
    "low64 = low + 64\n",
    "low1_1 = int(low * 1.1)\n",
    "low1_2 = int(low * 1.2)\n",
    "low1_3 = int(low * 1.3)\n",
    "low1_4 = int(low * 1.4)\n",
    "low1_5 = int(low * 1.5)\n",
    "\n",
    "MOM_DIM = {\n",
    "    \"convnext_small\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"maxvit_t\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"resnet152\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "    \"resnext101_64x4d\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "    \"swin_v2_s\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"vit_l_16\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"wide_resnet101_2\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "}\n",
    "NES_DIM = {\n",
    "    \"convnext_small\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"maxvit_t\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"resnet152\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"resnext101_64x4d\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "    \"swin_v2_s\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"vit_l_16\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"wide_resnet101_2\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "}\n",
    "ADAM_DIM = {    \n",
    "    \"convnext_small\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"maxvit_t\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "    \"resnet152\": {\"low\": low, \"high\": low1_1, \"p\": 0.5},\n",
    "    \"resnext101_64x4d\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "    \"swin_v2_s\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"vit_l_16\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"wide_resnet101_2\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "}\n",
    "NADAM_DIM = {\n",
    "    \"convnext_small\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"maxvit_t\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"resnet152\": {\"low\": low, \"high\": low1_1, \"p\": 0.5},\n",
    "    \"resnext101_64x4d\": {\"low\": low, \"high\": low1_1, \"p\": 0.5},\n",
    "    \"swin_v2_s\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"vit_l_16\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"wide_resnet101_2\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "}\n",
    "ADABELIEF_DIM = {\n",
    "    \"convnext_small\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"maxvit_t\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"resnet152\": {\"low\": low, \"high\": low1_1, \"p\": 0.5},\n",
    "    \"resnext101_64x4d\": {\"low\": low, \"high\": low1_3, \"p\": 0.5},\n",
    "    \"swin_v2_s\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"vit_l_16\": {\"low\": low, \"high\": low32, \"p\": 0.5},\n",
    "    \"wide_resnet101_2\": {\"low\": low, \"high\": low64, \"p\": 0.5},\n",
    "}\n",
    "\n",
    "for k in MOM_DIM.keys():\n",
    "    MOM_DIM[k][\"transform\"] = models.get_model_weights(k).DEFAULT.transforms()\n",
    "    NES_DIM[k][\"transform\"] = models.get_model_weights(k).DEFAULT.transforms()\n",
    "    ADAM_DIM[k][\"transform\"] = models.get_model_weights(k).DEFAULT.transforms()\n",
    "    NADAM_DIM[k][\"transform\"] = models.get_model_weights(k).DEFAULT.transforms()\n",
    "    ADABELIEF_DIM[k][\"transform\"] = models.get_model_weights(k).DEFAULT.transforms()\n",
    "\n",
    "MOM_TIM = {\n",
    "    \"convnext_small\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"maxvit_t\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnet152\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnext101_64x4d\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"swin_v2_s\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"vit_l_16\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"wide_resnet101_2\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "}\n",
    "NES_TIM = {\n",
    "    \"convnext_small\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"maxvit_t\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"resnet152\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"resnext101_64x4d\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"swin_v2_s\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"vit_l_16\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"wide_resnet101_2\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "}\n",
    "ADABELIEF_TIM = {\n",
    "    \"convnext_small\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"maxvit_t\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnet152\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnext101_64x4d\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"swin_v2_s\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"vit_l_16\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"wide_resnet101_2\": {\"kernel_size\":3, \"nsig\": 3},\n",
    "}\n",
    "ADAM_TIM = {\n",
    "    \"convnext_small\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"maxvit_t\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnet152\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"resnext101_64x4d\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"swin_v2_s\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"vit_l_16\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"wide_resnet101_2\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "}\n",
    "NADAM_TIM = {\n",
    "    \"convnext_small\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"maxvit_t\": {\"kernel_size\": 3, \"nsig\": 3},\n",
    "    \"resnet152\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"resnext101_64x4d\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"swin_v2_s\": {\"kernel_size\": 15, \"nsig\": 3},\n",
    "    \"vit_l_16\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "    \"wide_resnet101_2\": {\"kernel_size\": 1, \"nsig\": 3},\n",
    "}\n",
    "\n",
    "# SIM\n",
    "num_samples = 1\n",
    "eta = 0\n",
    "\n",
    "def gamma(num):\n",
    "    return [1 / 2 ** idx for idx in range(num)]\n",
    "\n",
    "MOM_ADMIX = {\n",
    "    \"convnext_small\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"maxvit_t\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"resnet152\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"swin_v2_s\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"vit_l_16\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "}\n",
    "NES_ADMIX = {\n",
    "    \"convnext_small\": {\"num_samples\": num_samples, \"gamma\": gamma(6), \"eta\": eta},\n",
    "    \"maxvit_t\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"resnet152\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"swin_v2_s\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"vit_l_16\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "}\n",
    "ADAM_ADMIX = {\n",
    "    \"convnext_small\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"maxvit_t\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"resnet152\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"swin_v2_s\": {\"num_samples\": num_samples, \"gamma\": gamma(2), \"eta\": eta},\n",
    "    \"vit_l_16\": {\"num_samples\": num_samples, \"gamma\": gamma(6), \"eta\": eta},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "}\n",
    "NADAM_ADMIX = {\n",
    "    \"convnext_small\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"maxvit_t\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"resnet152\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"swin_v2_s\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"vit_l_16\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "}\n",
    "ADABELIEF_ADMIX = {\n",
    "    \"convnext_small\": {\"num_samples\": num_samples, \"gamma\": gamma(6), \"eta\": eta},\n",
    "    \"maxvit_t\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"resnet152\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": num_samples, \"gamma\": gamma(5), \"eta\": eta},\n",
    "    \"swin_v2_s\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "    \"vit_l_16\": {\"num_samples\": num_samples, \"gamma\": gamma(7), \"eta\": eta},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": num_samples, \"gamma\": gamma(8), \"eta\": eta},\n",
    "}\n",
    "\n",
    "# ADMIX\n",
    "# MOM_ADMIX = {\n",
    "#     \"convnext_small\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"maxvit_t\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.5},\n",
    "#     \"resnet152\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"resnext101_64x4d\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"swin_v2_s\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.1},\n",
    "#     \"vit_l_16\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"wide_resnet101_2\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "# }\n",
    "# NES_ADMIX = {\n",
    "#     \"convnext_small\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"maxvit_t\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.1},\n",
    "#     \"resnet152\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"resnext101_64x4d\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"swin_v2_s\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.1},\n",
    "#     \"vit_l_16\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"wide_resnet101_2\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.3},\n",
    "# }\n",
    "# ADAM_ADMIX = {\n",
    "#     \"convnext_small\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"maxvit_t\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.5},\n",
    "#     \"resnet152\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"resnext101_64x4d\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"swin_v2_s\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.1},\n",
    "#     \"vit_l_16\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"wide_resnet101_2\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "# }\n",
    "# NADAM_ADMIX = {\n",
    "#     \"convnext_small\": {\"num_samples\": 5, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"maxvit_t\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.1},\n",
    "#     \"resnet152\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"resnext101_64x4d\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"swin_v2_s\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"vit_l_16\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"wide_resnet101_2\": {\"num_samples\": 7, \"gamma\": 0, \"eta\": 0.3},\n",
    "# }\n",
    "# ADABELIEF_ADMIX = {\n",
    "#     \"convnext_small\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"maxvit_t\": {\"num_samples\": 8, \"gamma\": 0, \"eta\": 0.5},\n",
    "#     \"resnet152\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"resnext101_64x4d\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"swin_v2_s\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"vit_l_16\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "#     \"wide_resnet101_2\": {\"num_samples\": 3, \"gamma\": 0, \"eta\": 0.2},\n",
    "# }\n",
    "\n",
    "MOM_VT = {\n",
    "    \"convnext_small\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"maxvit_t\": {\"num_samples\": 4, \"bound\": 1, \"dist\": \"normal\"},\n",
    "    \"resnet152\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": 8, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"swin_v2_s\": {\"num_samples\": 4, \"bound\": 1.5, \"dist\": \"normal\"},\n",
    "    \"vit_l_16\": {\"num_samples\": 8, \"bound\": 1.0, \"dist\": \"normal\"},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": 8, \"bound\": 2.0, \"dist\": \"uniform\"},\n",
    "}\n",
    "NES_VT = {\n",
    "    \"convnext_small\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"maxvit_t\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"resnet152\": {\"num_samples\": 4, \"bound\": 1.5, \"dist\": \"normal\"},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": 8, \"bound\": 2, \"dist\": \"normal\"},\n",
    "    \"swin_v2_s\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"vit_l_16\": {\"num_samples\": 8, \"bound\": 2.0, \"dist\": \"normal\"},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": 4, \"bound\": 2.0, \"dist\": \"normal\"},\n",
    "}\n",
    "ADAM_VT = {\n",
    "    \"convnext_small\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"maxvit_t\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"resnet152\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"swin_v2_s\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"vit_l_16\": {\"num_samples\": 8, \"bound\": 3.0, \"dist\": \"normal\"},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "}\n",
    "NADAM_VT = {\n",
    "    \"convnext_small\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"maxvit_t\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"resnet152\": {\"num_samples\": 8, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": 4, \"bound\": 2, \"dist\": \"uniform\"},\n",
    "    \"swin_v2_s\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"vit_l_16\": {\"num_samples\": 8, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": 8, \"bound\": 2.0, \"dist\": \"uniform\"},\n",
    "}\n",
    "ADABELIEF_VT = {\n",
    "    \"convnext_small\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"maxvit_t\": {\"num_samples\": 4, \"bound\": 1, \"dist\": \"normal\"},\n",
    "    \"resnet152\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "    \"resnext101_64x4d\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "    \"swin_v2_s\": {\"num_samples\": 4, \"bound\": .5, \"dist\": \"normal\"},\n",
    "    \"vit_l_16\": {\"num_samples\": 8, \"bound\": 1.0, \"dist\": \"normal\"},\n",
    "    \"wide_resnet101_2\": {\"num_samples\": 8, \"bound\": .5, \"dist\": \"uniform\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:59.982330Z",
     "iopub.status.busy": "2024-11-26T09:59:59.981952Z",
     "iopub.status.idle": "2024-11-26T09:59:59.986203Z",
     "shell.execute_reply": "2024-11-26T09:59:59.985373Z",
     "shell.execute_reply.started": "2024-11-26T09:59:59.982301Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ACT = \"linear\"\n",
    "# ACT = \"softsign\"\n",
    "# ACT = \"tanh\"\n",
    "# ACT = \"sigmoid\"\n",
    "# ACT = \"sign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T09:59:59.987626Z",
     "iopub.status.busy": "2024-11-26T09:59:59.987296Z",
     "iopub.status.idle": "2024-11-26T10:00:00.056759Z",
     "shell.execute_reply": "2024-11-26T10:00:00.055754Z",
     "shell.execute_reply.started": "2024-11-26T09:59:59.987575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MOMENTUM_HP = {\n",
    "    \"convnext_small\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"maxvit_t\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"resnet152\": {\"beta\": 0.8, \"activation\": ACT},\n",
    "    \"resnext101_64x4d\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"swin_v2_s\": {\"beta\": 1.0, \"activation\": ACT},\n",
    "    \"vit_l_16\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"wide_resnet101_2\": {\"beta\": .9, \"activation\": ACT},\n",
    "}\n",
    "NESTEROV_HP = {\n",
    "    \"convnext_small\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"maxvit_t\": {\"beta\": 1.0, \"activation\": ACT},\n",
    "    \"resnet152\": {\"beta\": 0.9, \"activation\": ACT},\n",
    "    \"resnext101_64x4d\": {\"beta\": 1., \"activation\": ACT},\n",
    "    \"swin_v2_s\": {\"beta\": 1.0, \"activation\": ACT},\n",
    "    \"vit_l_16\": {\"beta\": 1.0, \"activation\": ACT},\n",
    "    \"wide_resnet101_2\": {\"beta\": 1., \"activation\": ACT},\n",
    "}\n",
    "ADAM_HP = {\n",
    "    \"convnext_small\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"maxvit_t\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnet152\": {\"beta_1\": 0.7, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnext101_64x4d\": {\"beta_1\": 0.8, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"swin_v2_s\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"vit_l_16\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"wide_resnet101_2\": {\"beta_1\": 0.7, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "}\n",
    "NADAM_HP = {\n",
    "    \"convnext_small\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"maxvit_t\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnet152\": {\"beta_1\": 0.8, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnext101_64x4d\": {\"beta_1\": 0.9, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"swin_v2_s\": {\"beta_1\": 0.99, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"vit_l_16\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"wide_resnet101_2\": {\"beta_1\": 0.9, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "}\n",
    "ADABELIEF_HP = {\n",
    "    \"convnext_small\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"maxvit_t\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnet152\": {\"beta_1\": 0.7, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"resnext101_64x4d\": {\"beta_1\": 0.9, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"swin_v2_s\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"vit_l_16\": {\"beta_1\": 0.999, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "    \"wide_resnet101_2\": {\"beta_1\": 0.7, \"beta_2\": 0.999, \"delta\": 1e-8, \"activation\": ACT},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "TIME = datetime.now().strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "# SAVE_DIR = rf'/kaggle/working/{TIME.replace(\"/\", \"_\").replace(\":\", \"_\")}/non_targeted_white_box'\n",
    "# INPUT_DIR = \"/kaggle/input/nips-2017-adversarial-learning-development-set/images\"\n",
    "# INPUT_META = \"/kaggle/input/thesis-common/common.csv\"\n",
    "\n",
    "\n",
    "\n",
    "SAVE_DIR = os.getcwd() + f'/{TIME.replace(\"/\", \"_\").replace(\":\", \"_\")}'\n",
    "INPUT_DIR = r\"C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\"\n",
    "INPUT_META = r\"C:\\Users\\User\\Desktop\\Thesis\\common.csv\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_FIG = 795\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPS = 10\n",
    "ALPHA = 1\n",
    "N_ITER = 20\n",
    "TARGETED = False\n",
    "MODE = \"test\"\n",
    "SAVE_ADV = True\n",
    "BLACK_BOX_TEST = False\n",
    "DIM_ACT = False\n",
    "TIM_ACT = False\n",
    "ADMIX_ACT = False\n",
    "VT_ACT = False\n",
    "ENABLE_AMP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T10:00:00.058335Z",
     "iopub.status.busy": "2024-11-26T10:00:00.058063Z",
     "iopub.status.idle": "2024-11-26T10:00:00.067381Z",
     "shell.execute_reply": "2024-11-26T10:00:00.066651Z",
     "shell.execute_reply.started": "2024-11-26T10:00:00.058313Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def softsign(x):\n",
    "    return x / (1 + x.abs())\n",
    "\n",
    "def sign(x):\n",
    "    return x.sign()\n",
    "\n",
    "def tanh(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 2 * x.sigmoid() - 1\n",
    "\n",
    "def clipped_linear(x):\n",
    "    return torch.clamp(x, -1, 1)\n",
    "\n",
    "ACTIVATION = {\n",
    "    \"sign\":sign,\n",
    "    \"softsign\":softsign,\n",
    "    \"tanh\":tanh,\n",
    "    \"sigmoid\":sigmoid,\n",
    "    \"linear\":clipped_linear,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T10:00:00.069039Z",
     "iopub.status.busy": "2024-11-26T10:00:00.068712Z",
     "iopub.status.idle": "2024-11-26T10:00:00.123483Z",
     "shell.execute_reply": "2024-11-26T10:00:00.122831Z",
     "shell.execute_reply.started": "2024-11-26T10:00:00.069012Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "import json, os\n",
    "\n",
    "\n",
    "\n",
    "from piq.ssim import ssim \n",
    "\n",
    "\n",
    "\n",
    "from piq.fsim import fsim\n",
    "\n",
    "\n",
    "\n",
    "from piq.psnr import psnr\n",
    "\n",
    "\n",
    "\n",
    "from piq.vif import vif_p\n",
    "\n",
    "\n",
    "\n",
    "from piq.ms_ssim import multi_scale_ssim\n",
    "\n",
    "\n",
    "\n",
    "from piq.iw_ssim import information_weighted_ssim\n",
    "\n",
    "\n",
    "\n",
    "from piq.mdsi import mdsi\n",
    "\n",
    "\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "\n",
    "    np.random.seed(seed) \n",
    "\n",
    "\n",
    "\n",
    "    random.seed(seed)  \n",
    "\n",
    "\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model = model.to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        total = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        correct_classification = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # with torch.no_grad():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for path, images, labels in tqdm.tqdm(data_loader):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            images = images.to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            labels = labels.to(\"cuda\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            total += labels.size(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            correct += (predicted == labels).sum().item()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for p, q, l in zip(path, predicted, labels):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                 if q == l:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    correct_classification.append(p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return accuracy, correct_classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def attack_metadata(save_dir, time, amp, batch_size, alpha, eps, n_iter, act, num_fig,\n",
    "\n",
    "\n",
    "\n",
    "                    performed_attck, targeted, mode, black_box,\n",
    "\n",
    "\n",
    "\n",
    "                    mi_fgsm=None, ni_fgsm=None, agi_fgsm=None, adi_fgsm=None,\n",
    "\n",
    "\n",
    "\n",
    "                    rmsi_fgsm=None, ai_fgsm=None, ani_fgsm=None, nai_fgsm=None,\n",
    "\n",
    "\n",
    "\n",
    "                    yogi_fgsm=None, adai_fgsm=None, abi_fgsm=None,\n",
    "\n",
    "\n",
    "\n",
    "                    dim=None, tim=None, admix=None, vt=None):\n",
    "\n",
    "\n",
    "\n",
    "    metadata = {\n",
    "\n",
    "\n",
    "\n",
    "        \"Time\":time,\n",
    "\n",
    "\n",
    "\n",
    "        \"Enable_amp\":amp,\n",
    "\n",
    "\n",
    "\n",
    "        \"Hyperparameters\":{\"batch_size\":batch_size, \"alpha\":alpha, \"eps\":eps, \"n_iter\":n_iter,\n",
    "\n",
    "\n",
    "\n",
    "                        \"activation\":act, \"num_figure\":num_fig},\n",
    "\n",
    "\n",
    "\n",
    "        \"Mode\":mode, \"Black-Box\":black_box,\n",
    "\n",
    "\n",
    "\n",
    "        \"Attack\":performed_attck,\n",
    "\n",
    "\n",
    "\n",
    "        \"Targeted\":targeted,\n",
    "\n",
    "\n",
    "\n",
    "        \"DIM\":dim,\n",
    "\n",
    "\n",
    "\n",
    "        \"TIM\":tim,\n",
    "\n",
    "\n",
    "\n",
    "        \"ADMIX\":admix,\n",
    "\n",
    "\n",
    "\n",
    "        \"VT\":vt,\n",
    "\n",
    "\n",
    "\n",
    "        \"MI-FGSM\":mi_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"NI-FGSN\":ni_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"AGI-FGSM\":agi_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"ADI-FGSM\":adi_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"RMSI-FGSM\":rmsi_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"AI-FGSM\":ai_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"ANI-FGSM\":ani_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"NAI-FGSM\":nai_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"YOGI\":yogi_fgsm, \n",
    "\n",
    "\n",
    "\n",
    "        \"ADAI\":adai_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "        \"ADABELIEF\":abi_fgsm,\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    time = time.replace(\"/\", \"_\")\n",
    "\n",
    "\n",
    "\n",
    "    time = time.replace(\":\", \"_\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(f'{save_dir}/metadata.json', 'w') as file:\n",
    "\n",
    "\n",
    "\n",
    "        json.dump(metadata, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    print(metadata[\"Hyperparameters\"], metadata[\"Targeted\"])\n",
    "\n",
    "\n",
    "\n",
    "    return json.dumps(metadata, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(img, adv_img, verbose=False):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return: ssim, psnr, fsim, iw-ssim, ms-ssim, mdsi, vifp, mse, mae\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _ssim = ssim(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _psnr = psnr(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _fsim = fsim(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _iw_ssim = information_weighted_ssim(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _ms_ssim = multi_scale_ssim(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _mdsi = mdsi(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _vifp = vif_p(img, adv_img, data_range=1.0).item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _mse = float(torch.mean((img - adv_img) ** 2).cpu())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    _mae = float(torch.mean(torch.abs(img - adv_img)).cpu())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if verbose: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'SSIM: {_ssim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'PSNR: {_psnr}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'FSIM: {_fsim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'IW-SSIM: {_iw_ssim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'MS-SSIM: {_ms_ssim}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'MDSI: {_mdsi}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'VIFp: {_vifp}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'MSE: {_mse}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'MAE: {_mae}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return [_ssim, _psnr, _fsim, _iw_ssim, _ms_ssim, _mdsi, _vifp, _mse, _mae]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_result(m, att, targeted, metrics, metrics_average):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    t = PrettyTable([\"ITEM\", \"VALUE\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    t.add_row(['METHOD', f\"{m}_{att}\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    t.add_row([\"TARGETED\", targeted])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for idx in range(len(metrics)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        t.add_row([metrics[idx], metrics_average[idx]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(t)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_metadata(dir):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    files = os.listdir(dir)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    json_file = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if file.endswith('.json'):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            json_file = file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            break    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if json_file is None:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        raise FileNotFoundError(\"No metadata JSON file found in the directory\")    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    json_path = os.path.join(dir, json_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        metadata = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T10:00:00.126490Z",
     "iopub.status.busy": "2024-11-26T10:00:00.126064Z",
     "iopub.status.idle": "2024-11-26T10:00:00.133350Z",
     "shell.execute_reply": "2024-11-26T10:00:00.132447Z",
     "shell.execute_reply.started": "2024-11-26T10:00:00.126469Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def black_box(models, model_names, transforms, data):\n",
    "\n",
    "\n",
    "\n",
    "    acc, success = [], []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    misclassified = np.zeros((len(model_names), BATCH_SIZE))\n",
    "\n",
    "    misclassified_images = [[] for _ in model_names]\n",
    "\n",
    "\n",
    "\n",
    "    for idx, m in enumerate(model_names):\n",
    "\n",
    "\n",
    "\n",
    "        t = transforms[m]\n",
    "\n",
    "\n",
    "\n",
    "        model = models[m]\n",
    "\n",
    "\n",
    "\n",
    "        path, adv_image, label, target_label = data\n",
    "\n",
    "\n",
    "\n",
    "        adv_image = t(adv_image)\n",
    "\n",
    "\n",
    "\n",
    "        outputs = model(adv_image)\n",
    "\n",
    "\n",
    "\n",
    "        predicted = outputs.max(1)[1]\n",
    "\n",
    "\n",
    "\n",
    "        acc.append((label == predicted.cpu()).sum().item())\n",
    "\n",
    "\n",
    "\n",
    "        for jdx in range(label.size(0)):\n",
    "\n",
    "            if label[jdx] != predicted.cpu()[jdx]:\n",
    "\n",
    "                misclassified[idx, jdx] = 1\n",
    "\n",
    "\n",
    "\n",
    "        misclassified_images[idx].extend([path[i] for i in range(len(path)) if label[i] != predicted[i].cpu()])\n",
    "\n",
    "        success.append((target_label == predicted.cpu()).sum().item())\n",
    "\n",
    "\n",
    "\n",
    "    for idx in range(len(misclassified_images)):\n",
    "\n",
    "        misclassified_images[idx] = \"\\n\".join(misclassified_images[idx])\n",
    "\n",
    "\n",
    "\n",
    "    return acc, misclassified, misclassified_images, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T10:00:00.134717Z",
     "iopub.status.busy": "2024-11-26T10:00:00.134469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM: False TIM: False Admix: False VT: False\n",
      "{'batch_size': 1, 'alpha': 1, 'eps': 10, 'n_iter': 20, 'activation': 'linear', 'num_figure': 795} False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Momentum/1.0:  20%|██        | 1/5 [00:01<00:07,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\02eb799d147d5f91.png 20 tensor(884) tensor(772) tensor(624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Momentum/1.0:  40%|████      | 2/5 [00:03<00:05,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\38546e7d7136c2ab.png 20 tensor(599) tensor(113) tensor(599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Momentum/2.0:  60%|██████    | 3/5 [00:05<00:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\b89dbfcc49dcf156.png 20 tensor(663) tensor(466) tensor(888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Momentum/3.0:  80%|████████  | 4/5 [00:06<00:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\7b6a9bf5b175e3b2.png 20 tensor(591) tensor(598) tensor(557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Momentum/4.0: 100%|██████████| 5/5 [00:08<00:00,  1.73s/it]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  ssim_ /= misclassified\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:195: RuntimeWarning: invalid value encountered in divide\n",
      "  psnr_ /= misclassified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\72f96c6dc5df2de8.png 20 tensor(778) tensor(783) tensor(884)\n",
      "+----------+--------------------+\n",
      "|   ITEM   |       VALUE        |\n",
      "+----------+--------------------+\n",
      "|  METHOD  | resnet152_Momentum |\n",
      "| TARGETED |       False        |\n",
      "|   SSIM   |        0.0         |\n",
      "|   PSNR   |        0.0         |\n",
      "|   FSIM   |        0.0         |\n",
      "| IW-SSIM  |        0.0         |\n",
      "| MS-SSIM  |        0.0         |\n",
      "|   MDSI   |        0.0         |\n",
      "|  VIF_P   |        0.0         |\n",
      "|   MSE    |        0.0         |\n",
      "|   MAE    |        0.0         |\n",
      "|   STEP   |        0.0         |\n",
      "|   LOSS   |        0.0         |\n",
      "|  NOISE   |        0.0         |\n",
      "| SUCCESS  |        4.0         |\n",
      "+----------+--------------------+\n",
      "Checkpoint Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Nesterov/1.0:  20%|██        | 1/5 [00:01<00:06,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\02eb799d147d5f91.png 20 tensor(884) tensor(772) tensor(624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Nesterov/1.0:  40%|████      | 2/5 [00:03<00:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\38546e7d7136c2ab.png 20 tensor(599) tensor(113) tensor(599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Nesterov/2.0:  60%|██████    | 3/5 [00:04<00:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\b89dbfcc49dcf156.png 20 tensor(710) tensor(466) tensor(888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Nesterov/3.0:  80%|████████  | 4/5 [00:06<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\7b6a9bf5b175e3b2.png 20 tensor(591) tensor(598) tensor(557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Nesterov/4.0: 100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  ssim_ /= misclassified\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:195: RuntimeWarning: invalid value encountered in divide\n",
      "  psnr_ /= misclassified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\72f96c6dc5df2de8.png 20 tensor(539) tensor(783) tensor(884)\n",
      "+----------+--------------------+\n",
      "|   ITEM   |       VALUE        |\n",
      "+----------+--------------------+\n",
      "|  METHOD  | resnet152_Nesterov |\n",
      "| TARGETED |       False        |\n",
      "|   SSIM   |        0.0         |\n",
      "|   PSNR   |        0.0         |\n",
      "|   FSIM   |        0.0         |\n",
      "| IW-SSIM  |        0.0         |\n",
      "| MS-SSIM  |        0.0         |\n",
      "|   MDSI   |        0.0         |\n",
      "|  VIF_P   |        0.0         |\n",
      "|   MSE    |        0.0         |\n",
      "|   MAE    |        0.0         |\n",
      "|   STEP   |        0.0         |\n",
      "|   LOSS   |        0.0         |\n",
      "|  NOISE   |        0.0         |\n",
      "| SUCCESS  |        4.0         |\n",
      "+----------+--------------------+\n",
      "Checkpoint Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Adam/1.0:  20%|██        | 1/5 [00:01<00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\02eb799d147d5f91.png 20 tensor(668) tensor(772) tensor(624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Adam/2.0:  40%|████      | 2/5 [00:02<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\38546e7d7136c2ab.png 20 tensor(283) tensor(113) tensor(599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Adam/3.0:  60%|██████    | 3/5 [00:04<00:03,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\b89dbfcc49dcf156.png 20 tensor(832) tensor(466) tensor(888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Adam/4.0:  80%|████████  | 4/5 [00:05<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\7b6a9bf5b175e3b2.png 20 tensor(591) tensor(598) tensor(557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_Adam/5.0: 100%|██████████| 5/5 [00:07<00:00,  1.48s/it]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  ssim_ /= misclassified\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:195: RuntimeWarning: invalid value encountered in divide\n",
      "  psnr_ /= misclassified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\72f96c6dc5df2de8.png 20 tensor(843) tensor(783) tensor(884)\n",
      "+----------+----------------+\n",
      "|   ITEM   |     VALUE      |\n",
      "+----------+----------------+\n",
      "|  METHOD  | resnet152_Adam |\n",
      "| TARGETED |     False      |\n",
      "|   SSIM   |      0.0       |\n",
      "|   PSNR   |      0.0       |\n",
      "|   FSIM   |      0.0       |\n",
      "| IW-SSIM  |      0.0       |\n",
      "| MS-SSIM  |      0.0       |\n",
      "|   MDSI   |      0.0       |\n",
      "|  VIF_P   |      0.0       |\n",
      "|   MSE    |      0.0       |\n",
      "|   MAE    |      0.0       |\n",
      "|   STEP   |      0.0       |\n",
      "|   LOSS   |      0.0       |\n",
      "|  NOISE   |      0.0       |\n",
      "| SUCCESS  |      5.0       |\n",
      "+----------+----------------+\n",
      "Checkpoint Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_NAdam/1.0:  20%|██        | 1/5 [00:01<00:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\02eb799d147d5f91.png 20 tensor(668) tensor(772) tensor(624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_NAdam/2.0:  40%|████      | 2/5 [00:02<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\38546e7d7136c2ab.png 20 tensor(365) tensor(113) tensor(599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_NAdam/3.0:  60%|██████    | 3/5 [00:04<00:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\b89dbfcc49dcf156.png 20 tensor(710) tensor(466) tensor(888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_NAdam/4.0:  80%|████████  | 4/5 [00:05<00:01,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\7b6a9bf5b175e3b2.png 20 tensor(591) tensor(598) tensor(557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_NAdam/5.0: 100%|██████████| 5/5 [00:07<00:00,  1.44s/it]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  ssim_ /= misclassified\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:195: RuntimeWarning: invalid value encountered in divide\n",
      "  psnr_ /= misclassified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\72f96c6dc5df2de8.png 20 tensor(843) tensor(783) tensor(884)\n",
      "+----------+-----------------+\n",
      "|   ITEM   |      VALUE      |\n",
      "+----------+-----------------+\n",
      "|  METHOD  | resnet152_NAdam |\n",
      "| TARGETED |      False      |\n",
      "|   SSIM   |       0.0       |\n",
      "|   PSNR   |       0.0       |\n",
      "|   FSIM   |       0.0       |\n",
      "| IW-SSIM  |       0.0       |\n",
      "| MS-SSIM  |       0.0       |\n",
      "|   MDSI   |       0.0       |\n",
      "|  VIF_P   |       0.0       |\n",
      "|   MSE    |       0.0       |\n",
      "|   MAE    |       0.0       |\n",
      "|   STEP   |       0.0       |\n",
      "|   LOSS   |       0.0       |\n",
      "|  NOISE   |       0.0       |\n",
      "| SUCCESS  |       5.0       |\n",
      "+----------+-----------------+\n",
      "Checkpoint Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_AdaBelief/1.0:  20%|██        | 1/5 [00:01<00:05,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\02eb799d147d5f91.png 20 tensor(884) tensor(772) tensor(624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_AdaBelief/1.0:  40%|████      | 2/5 [00:02<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\38546e7d7136c2ab.png 20 tensor(599) tensor(113) tensor(599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_AdaBelief/2.0:  60%|██████    | 3/5 [00:04<00:02,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\b89dbfcc49dcf156.png 20 tensor(832) tensor(466) tensor(888)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_AdaBelief/3.0:  80%|████████  | 4/5 [00:06<00:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\7b6a9bf5b175e3b2.png 20 tensor(591) tensor(598) tensor(557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "resnet152_AdaBelief/4.0: 100%|██████████| 5/5 [00:07<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Thesis\\dataset\\images\\72f96c6dc5df2de8.png 20 tensor(843) tensor(783) tensor(884)\n",
      "+----------+---------------------+\n",
      "|   ITEM   |        VALUE        |\n",
      "+----------+---------------------+\n",
      "|  METHOD  | resnet152_AdaBelief |\n",
      "| TARGETED |        False        |\n",
      "|   SSIM   |         0.0         |\n",
      "|   PSNR   |         0.0         |\n",
      "|   FSIM   |         0.0         |\n",
      "| IW-SSIM  |         0.0         |\n",
      "| MS-SSIM  |         0.0         |\n",
      "|   MDSI   |         0.0         |\n",
      "|  VIF_P   |         0.0         |\n",
      "|   MSE    |         0.0         |\n",
      "|   MAE    |         0.0         |\n",
      "|   STEP   |         0.0         |\n",
      "|   LOSS   |         0.0         |\n",
      "|  NOISE   |         0.0         |\n",
      "| SUCCESS  |         4.0         |\n",
      "+----------+---------------------+\n",
      "Checkpoint Saved...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:194: RuntimeWarning: invalid value encountered in divide\n",
      "  ssim_ /= misclassified\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14084\\3451330725.py:195: RuntimeWarning: invalid value encountered in divide\n",
      "  psnr_ /= misclassified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd, numpy as np\n",
    "import os, tqdm, torch\n",
    "import tifffile as tiff\n",
    "import random\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "def main(model_names):\n",
    "    # Mean and Std of training set\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    inv_transform = transforms.Compose([\n",
    "        transforms.Normalize(\n",
    "            mean=[-m / s for m, s in zip(MEAN, STD)],\n",
    "            std=[1 / s for s in STD]        \n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Data collection for further analysis\n",
    "    results = {\n",
    "        \"MODEL\":[], \"CATEGORY\":[], \"SSIM\":[], \"PSNR\":[], \n",
    "        \"FSIM\":[], \"IW-SSIM\":[], \"MS-SSIM\":[], \"MDSI\":[],\n",
    "        \"VIF_P\":[], \"MSE\":[], \"MAE\":[], \n",
    "        \"STEP\":[], \"LOSS\":[], \"NOISE\":[],\n",
    "        \"SUCCESS\":[], \"FAIL\":[],\n",
    "        \"TRUTH\":[], \"TARGET\":[], \"PREDICTED\":[]\n",
    "    }\n",
    "    metrics = list(results.keys())[2:15]\n",
    "\n",
    "    INTER_DIR = \"targeted\" if TARGETED else \"non_targeted\"\n",
    "    INDEX = []\n",
    "    print(\"DIM:\", DIM_ACT, \"TIM:\", TIM_ACT, \"Admix:\", ADMIX_ACT, \"VT:\", VT_ACT)\n",
    "    # Perform white box attack to each models\n",
    "    # Veryyy time-consuming\n",
    "    ACC, SUCCESS, MISCLASSIFIED = [], [], []\n",
    "    MISCLASSIFIED_IMAGES = []\n",
    "    BB_SSIM, BB_PSNR = [], []\n",
    "    INDEX_BLACK_BOX, CATEGORY, WHITE_BOX, BLACK_BOX = [], [], [], []\n",
    "\n",
    "    models_ = {}\n",
    "    transforms_ = {}\n",
    "\n",
    "    for m in model_names:\n",
    "        model = models.get_model(m, weights=\"DEFAULT\")\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(\"cuda\").eval()\n",
    "        weights = models.get_model_weights(m).DEFAULT\n",
    "        transform = weights.transforms()\n",
    "        models_[m] = model\n",
    "        transforms_[m] = transform\n",
    "\n",
    "    for idx, m in enumerate(model_names):\n",
    "        model = models_[m]\n",
    "        transform = transforms_[m]\n",
    "        dataset = ImageCSVDataset(INPUT_META, INPUT_DIR, NUM_FIG, transform, mode=MODE)\n",
    "        dataloader = DataLoader(dataset, shuffle=False, pin_memory=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "        HP = [ALPHA, EPS, MEAN, STD, N_ITER, DEVICE]\n",
    "        attacks = {\n",
    "            \"Momentum\": Momentum(\n",
    "                *HP, \n",
    "                tim=MOM_TIM[m], \n",
    "                dim=MOM_DIM[m], \n",
    "                **MOMENTUM_HP[m], \n",
    "                admix=MOM_ADMIX[m] if ADMIX_ACT else None,\n",
    "                vt=MOM_VT[m] if VT_ACT else None\n",
    "            ),\n",
    "            \"Nesterov\": Nesterov(\n",
    "                *HP, \n",
    "                tim=NES_TIM[m], \n",
    "                dim=NES_DIM[m], \n",
    "                **NESTEROV_HP[m], \n",
    "                admix=NES_ADMIX[m] if ADMIX_ACT else None,  \n",
    "                vt=NES_VT[m] if VT_ACT else None           \n",
    "            ),\n",
    "            \"Adam\": Adam(\n",
    "                *HP, \n",
    "                tim=ADAM_TIM[m], \n",
    "                dim=ADAM_DIM[m], \n",
    "                **ADAM_HP[m], \n",
    "                admix=ADAM_ADMIX[m] if ADMIX_ACT else None, \n",
    "                vt=ADAM_VT[m] if VT_ACT else None           \n",
    "            ),\n",
    "            \"NAdam\": NAdam(\n",
    "                *HP, \n",
    "                tim=NADAM_TIM[m], \n",
    "                dim=NADAM_DIM[m], \n",
    "                **NADAM_HP[m], \n",
    "                admix=NADAM_ADMIX[m] if ADMIX_ACT else None, \n",
    "                vt=NADAM_VT[m] if VT_ACT else None           \n",
    "            ),\n",
    "            \"AdaBelief\": AdaBelief(\n",
    "                *HP, \n",
    "                tim=ADABELIEF_TIM[m], \n",
    "                dim=ADABELIEF_DIM[m], \n",
    "                **ADABELIEF_HP[m], \n",
    "                admix=ADABELIEF_ADMIX[m] if ADMIX_ACT else None, \n",
    "                vt=ADABELIEF_VT[m] if VT_ACT else None           \n",
    "            ),\n",
    "        }\n",
    "\n",
    "\n",
    "        if ACT != \"sign\":\n",
    "            pass\n",
    "            # attacks[\"AdaDelta\"] = AdaDelta(*HP, **ADADELTA_HP[m], **MISC),\n",
    "            # attacks[\"RMSprop\"] = AdaDelta(*HP, **RMSPROP_HP[m], **MISC),\n",
    "\n",
    "\n",
    "        performed_attack = list(attacks.keys())\n",
    "\n",
    "\n",
    "\n",
    "        attack_metadata(SAVE_DIR, TIME, ENABLE_AMP, BATCH_SIZE, ALPHA, EPS, N_ITER, ACT, NUM_FIG,\n",
    "            performed_attack, TARGETED, MODE, BLACK_BOX_TEST,\n",
    "            MOMENTUM_HP if \"Momentum\" in performed_attack else None,\n",
    "            NESTEROV_HP if \"Nesterov\" in performed_attack else None,\n",
    "            None, None, None,\n",
    "            ADAM_HP if \"Adam\" in performed_attack else None,\n",
    "            None,\n",
    "            NADAM_HP if \"NAdam\" in performed_attack else None,\n",
    "            None, None,\n",
    "            ADABELIEF_HP if \"AdaBelief\" in performed_attack else None,\n",
    "            # Since the transforms object is not JSON serializable\n",
    "            # None,\n",
    "            # {k: {key: val for key, val in v.items() if key != \"transform\"} for k, v in DIM.items()} if DIM_ACT else None,\n",
    "            # TIM if TIM_ACT else None,\n",
    "            # ADMIX if ADMIX_ACT else None,\n",
    "            # VT_ if VT_ACT else None\n",
    "            None, None, None, None\n",
    "        )\n",
    "\n",
    "        for jdx, att in enumerate(attacks):\n",
    "            set_seed(226)\n",
    "            ssim_, psnr_ = np.zeros(len(model_names)), np.zeros(len(model_names))\n",
    "            acc, success = np.zeros(len(model_names)), np.zeros(len(model_names))\n",
    "            misclassified = np.zeros(len(model_names))\n",
    "            misclassified_images = [\"\" for _ in model_names]\n",
    "            metrics_ave = np.zeros(len(metrics))\n",
    "            fails, truths, predictions, targets = [], [], [], []\n",
    "            os.makedirs(f\"{SAVE_DIR}/{INTER_DIR}_{m}/{att}\", exist_ok=True)\n",
    "            progress = tqdm.tqdm(dataloader, desc=f\"{m}_{att}\")\n",
    "            for path, image, label, target_label in progress:\n",
    "                # Mixed precision may cause different result\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float32, enabled=ENABLE_AMP):\n",
    "                    adv, predicted, l, perturb, n = attacks[att].forward(model, image, label, \n",
    "                                                                        target_label if TARGETED else None)\n",
    "                predicted = predicted.cpu()\n",
    "                metrics_ave[12] += (label != predicted).sum().item() if not TARGETED else (target_label == predicted).sum().item()\n",
    "\n",
    "                if BLACK_BOX_TEST:\n",
    "                    adv_img = inv_transform(adv)\n",
    "                    acc_, mis_, mis_images_, success_ = black_box(models_, model_names, transforms_, [path, adv_img, label, target_label])\n",
    "                    acc += acc_\n",
    "                    success += success_\n",
    "                    misclassified += np.sum(mis_, axis=1)\n",
    "                    for pdx in range(len(misclassified_images)):\n",
    "                        misclassified_images[pdx] += (\"\\n\" + mis_images_[pdx])\n",
    "                for kdx in range(image.size(0)):\n",
    "                    adv_img = inv_transform(adv[kdx]).clamp(0, 1)\n",
    "                    if SAVE_ADV:\n",
    "                        adv_img_t = adv_img.cpu().numpy().transpose(1, 2, 0)\n",
    "                        tiff.imwrite(f\"{SAVE_DIR}/{INTER_DIR}_{m}/{att}/{os.path.basename(path[kdx]).replace('.png', '.tiff')}\", adv_img_t)\n",
    "                    if ((not TARGETED) and (label[kdx] == predicted[kdx]) or (TARGETED and (target_label[kdx] != predicted[kdx]))): \n",
    "                        fails.append(os.path.basename(path[kdx]))\n",
    "                        truths.append(str(label[kdx].item()))\n",
    "                        predictions.append(str(predicted[kdx].item()))\n",
    "                        if TARGETED:\n",
    "                            targets.append(str(target_label[kdx].item()))\n",
    "                        print(path[kdx], n, predicted[kdx], target_label[kdx], label[kdx])\n",
    "                    elif (TARGETED and (target_label[kdx] == predicted[kdx])) or ((not TARGETED) and (label[kdx] != predicted[kdx])):\n",
    "                        perturb = (inv_transform(perturb.unsqueeze(0)).cpu())\n",
    "                        metrics_ave[9] += n # Step\n",
    "                        metrics_ave[10] += l    # Loss    \n",
    "                        metrics_ave[11] += torch.norm(perturb, 2).mean().item() # Noise\n",
    "                        img = inv_transform(image[kdx])\n",
    "                        img = img.unsqueeze(0).to(\"cuda\")\n",
    "                        adv_img = adv_img.unsqueeze(0)\n",
    "                        computed_values = compute_metrics(img, adv_img)\n",
    "\n",
    "                        if BLACK_BOX_TEST:\n",
    "                            for idx in range(len(model_names)):\n",
    "                                    if mis_[idx, kdx]:\n",
    "                                        ssim_[idx] += computed_values[0]\n",
    "                                        psnr_[idx] += computed_values[1]\n",
    "                        for pdx in range(len(computed_values)):\n",
    "                            metrics_ave[pdx] += computed_values[pdx]\n",
    "\n",
    "                progress.set_description(f\"{m}_{att}/{metrics_ave[-1]}\")\n",
    "\n",
    "            ssim_ /= misclassified\n",
    "            psnr_ /= misclassified\n",
    "            metrics_ave[:-1] /= metrics_ave[-1]\n",
    "\n",
    "            for pdx, key in enumerate(metrics):\n",
    "                results[key].append(metrics_ave[pdx])\n",
    "\n",
    "            if BLACK_BOX_TEST:\n",
    "                # Checkpoint for Black-Box Attack\n",
    "                INDEX_BLACK_BOX.extend([f\"{m}_{att}\"] * len(model_names))\n",
    "                CATEGORY.extend([att] * len(model_names))\n",
    "                WHITE_BOX.extend([m] * len(model_names))\n",
    "                BLACK_BOX.extend(model_names)\n",
    "                ACC.extend(acc)\n",
    "                BB_PSNR.extend(psnr_)\n",
    "                BB_SSIM.extend(ssim_)\n",
    "                MISCLASSIFIED.extend(misclassified)\n",
    "                MISCLASSIFIED_IMAGES.extend(misclassified_images)\n",
    "                SUCCESS.extend(success)\n",
    "                pd.DataFrame({\n",
    "                    \"CATEGORY\":CATEGORY, \"WHITE_BOX\":WHITE_BOX, \"BLACK_BOX\":BLACK_BOX, \n",
    "                    \"SSIM\":BB_SSIM, \"PSNR\":BB_PSNR,\n",
    "                    \"ACC\":ACC, \n",
    "                    \"MISCLASSIFIED\":MISCLASSIFIED, \"SUCCESS\": SUCCESS,\n",
    "                    \"MISCLASSIFIED_IMAGES\":MISCLASSIFIED_IMAGES\n",
    "                }, index=INDEX_BLACK_BOX).to_csv(f\"checkpoint.csv\")\n",
    "\n",
    "            display_result(m, att, TARGETED, metrics, metrics_ave)\n",
    "            results[\"CATEGORY\"].append(att)\n",
    "            results[\"MODEL\"].append(m)\n",
    "            results[\"FAIL\"].append('\\n'.join(fails))\n",
    "            results[\"TRUTH\"].append(','.join(truths))\n",
    "            results[\"TARGET\"].append(','.join(targets))\n",
    "            results[\"PREDICTED\"].append(','.join(predictions))\n",
    "            INDEX.append(f\"{m}_{att}\")\n",
    "            # Checkpoint for White-Box Attack\n",
    "            pd.DataFrame(results, index=INDEX).to_csv(f\"{SAVE_DIR}/result.csv\")\n",
    "            print(\"Checkpoint Saved...\")\n",
    "\n",
    "model_names = [\n",
    "    \"resnet152\",\n",
    "    \"convnext_small\",\n",
    "    \"resnext101_64x4d\",\n",
    "    \"wide_resnet101_2\",\n",
    "    \"maxvit_t\",\n",
    "    \"swin_v2_s\",\n",
    "    \"vit_l_16\"\n",
    "]\n",
    "\n",
    "main(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\results\\\\cv'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1503,
     "sourceId": 2703,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5307098,
     "sourceId": 8821674,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "SnapHealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
